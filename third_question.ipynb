{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor contractions\n",
    "\n",
    "The following code performs the contraction:\n",
    "\n",
    "$$\n",
    "M_{pqrs} = \\sum_{ABCD} S_{pA}T_{qB} U_{rC} V_{sD} I_{ABCD}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def contract_to_M(I: np.ndarray, S: np.ndarray, T: np.ndarray, U: np.ndarray, V:np.ndarray) -> np.ndarray:\n",
    "    M = np.zeros((S.shape[0], T.shape[0], U.shape[0], V.shape[0]))\n",
    "\n",
    "    for p in range(M.shape[0]):\n",
    "        for q in range(M.shape[1]):\n",
    "            for r in range(M.shape[2]):\n",
    "                for s in range(M.shape[3]):\n",
    "                    for A in range(I.shape[0]):\n",
    "                        for B in range(I.shape[1]):\n",
    "                            for C in range(I.shape[2]):\n",
    "                                for D in range(I.shape[3]):\n",
    "                                    M[p, q, r, s] += S[p, A] * T[q, B] * U[r, C] * V[s, D] * I[A, B, C, D]\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the _Big-O_ estimates for the number of FLOPS and the amount of memory required?\n",
    "2. How would you check that your estimates are in the right ballpark?\n",
    "3. Rearrange the function such that the _Big-O_ estimate for the number of FLOPS is minimized. How are the _Big-O_ estimates for the memory affected?\n",
    "4. Write tests to make sure the behaviour is consistent between the original and the rearranged versions of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:blue'> Answer </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well let's have a look on this problem using **quimb**. Suppose we have random tensors that one of them **I** has common index with others **S, T, U, and V**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import quimb as qu\n",
    "import quimb.tensor as qtn \n",
    "\n",
    "I = qtn.rand_tensor(shape = [4,4,4,4], inds = ['A', 'B', 'C', 'D'], tags='I')\n",
    "S = qtn.rand_tensor(shape = [3,4], inds = ['p','A'], tags='S')\n",
    "T = qtn.rand_tensor(shape = [3,4], inds = ['q','B'], tags='T')\n",
    "U = qtn.rand_tensor(shape = [3,4], inds = ['r','C'], tags='U')\n",
    "V = qtn.rand_tensor(shape = [3,4], inds = ['s','D'], tags='V')\n",
    "\n",
    "res = S@T@U@V@I\n",
    "res.draw(node_color='maroon',\n",
    "         node_outline_darkness=.1,\n",
    "         figsize=(10,3),\n",
    "         edge_color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. What are the _Big-O_ estimates for the number of FLOPS and the amount of memory required?**\n",
    "\n",
    "Well, to answer to this question, I would say we have some indexes that will contract with each others and we can call them as an inner indexes (A, B, C, D) and some outer indexes (p, q, r, s) that doesn't have any contractions. \n",
    "\n",
    "In the code that is provided by the host we can see $8$ nested loops which increase the computational cost by $O(N^8)$ where $N$ represents the dimensions of the each matrices.\n",
    "\n",
    "For the memory requirement, I would say that RAM is the place to store inputs and outputs. Then we should calculate how much storage we need for input matrix and how much for the output. Here the point is about largest term among input matrixes that always dominant and take the major part of the memory and no need to consider low dimension tensors in the presence of large tensors. Consider this explanation the largest tensor among input tensors is $I_{ABCD}$ which its respective dimension is  $O(N^4)$ and the output matrix is $M_{pqrs}$ with respective dimension $O(M^4)$. This tells us that the memory usage is $I+M$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How would you check that your estimates are in the right ballpark?**\n",
    "\n",
    "Well mainly the structure of the code tells us how much it is efficient but for check the code we have some tools like *time* library for evaluation the runtime. \n",
    "\n",
    "Also for evaluating the memory usage we can use libraries like *tracemalloc* which is effectively monitor the memory usage. \n",
    "\n",
    "Moreover for the CPU usage in some cases we should use *psutil* library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Rearrange the function such that the _Big-O_ estimate for the number of FLOPS is minimized. How are the _Big-O_ estimates for the memory affected?**\n",
    "\n",
    "For this part I will rearrange the code in two ways. one of them using *np.tensordot* and another one using *np.einsum*. First lets make a class the funstions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class tensor_contract():\n",
    "    def __init__(self, I, S, T, U, V):\n",
    "        self.I = I\n",
    "        self.S = S\n",
    "        self.T = T\n",
    "        self.U = U\n",
    "        self.V = V\n",
    "\n",
    "    def contract_to_M(self):\n",
    "        M = np.zeros((self.S.shape[0], self.T.shape[0], self.U.shape[0], self.V.shape[0]))\n",
    "\n",
    "        for p in range(M.shape[0]):\n",
    "            for q in range(M.shape[1]):\n",
    "                for r in range(M.shape[2]):\n",
    "                    for s in range(M.shape[3]):\n",
    "                        for A in range(self.I.shape[0]):\n",
    "                            for B in range(self.I.shape[1]):\n",
    "                                for C in range(self.I.shape[2]):\n",
    "                                    for D in range(self.I.shape[3]):\n",
    "                                        M[p, q, r, s] += self.S[p, A] * self.T[q, B] * self.U[r, C] * self.V[s, D] * self.I[A, B, C, D]\n",
    "\n",
    "        return M\n",
    "\n",
    "    def contract_to_M_tensordot(self):\n",
    "        M = np.tensordot(self.I, self.V, axes=(3, 1)) \n",
    "        M = np.tensordot(M, self.U, axes=(2, 1)) \n",
    "        M = np.tensordot(M, self.T, axes=(1, 1)) \n",
    "        M = np.tensordot(M, self.S, axes=(0, 1))  \n",
    "        return M\n",
    "\n",
    "    def contract_to_M_einsum(self):\n",
    "        M = np.einsum('ABCD, pA, qB, rC, sD->pqrs', self.I, self.S, self.T, self.U, self.V)\n",
    "        return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a look on the time evaluation for these three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.random.rand(4, 4, 4, 4)\n",
    "S = np.random.rand(3, 4)\n",
    "T = np.random.rand(3, 4)\n",
    "U = np.random.rand(3, 4)\n",
    "V = np.random.rand(3, 4)\n",
    "\n",
    "contractor = tensor_contract(I, S, T, U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_code_runtime: 0.09019947052001953\n",
      "tensordot_runtime: 0.0009753704071044922\n",
      "einsum_runtime: 0.0006814002990722656\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_h = time.time()\n",
    "host = contractor.contract_to_M()\n",
    "end_h = time.time()\n",
    "print(\"host_code_runtime:\", end_h - start_h)\n",
    "start_d = time.time()\n",
    "M_tdot = contractor.contract_to_M_tensordot()\n",
    "end_d = time.time()\n",
    "print(\"tensordot_runtime:\", end_d - start_d)\n",
    "start_e = time.time()\n",
    "M_einsum = contractor.contract_to_M_einsum()\n",
    "end_e = time.time()\n",
    "print(\"einsum_runtime:\", end_e - start_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_peak_memory_usage: 21460\n",
      "tensordot_peak_memory_usage: 19920\n",
      "einsum_peak_memory_usage: 398160\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "\n",
    "tracemalloc.start()\n",
    "result = contractor.contract_to_M()\n",
    "_, h_peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop() \n",
    "print(\"host_peak_memory_usage:\", h_peak_memory)\n",
    "\n",
    "tracemalloc.start()\n",
    "result = contractor.contract_to_M_tensordot()\n",
    "_, d_peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop() \n",
    "print(\"tensordot_peak_memory_usage:\", d_peak_memory)\n",
    "\n",
    "tracemalloc.start()\n",
    "result = contractor.contract_to_M_einsum()\n",
    "_, e_peak_memory = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop() \n",
    "print(\"einsum_peak_memory_usage:\", e_peak_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Write tests to make sure the behaviour is consistent between the original and the rearranged versions of the code.**\n",
    "\n",
    "To become ensure about the original and rearranged version I would say that we can use *np.allclose* in a function that return us the boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_contract(func_1, func_2):\n",
    "    if np.allclose(func_1, func_2) == True:\n",
    "        return 'successful'\n",
    "    else:\n",
    "        return 'unsuccessful'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am considering the host approach as a true answer and I will compare the other codes with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test result for the tensordot approach is unsuccessful\n",
      "the test result for the einsum approach is successful\n"
     ]
    }
   ],
   "source": [
    "host = contractor.contract_to_M()\n",
    "M_tdot = contractor.contract_to_M_tensordot()\n",
    "M_einsum = contractor.contract_to_M_einsum()\n",
    "\n",
    "print('the test result for the tensordot approach is', test_contract(host, M_tdot))\n",
    "print('the test result for the einsum approach is', test_contract(host, M_einsum))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
